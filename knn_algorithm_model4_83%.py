# -*- coding: utf-8 -*-
"""KNN Algorithm (83% accuracy) - Data Mining project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O47IVqqFuv-y1VeaJ53WrRlKHJvffKtF
"""

# Import libraries
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# Load the data:
train_data_KNN = pd.read_csv("census-income.data.csv")
test_data_KNN = pd.read_csv("census-income.test.csv")

# Trim spaces and remove periods from the target column to standardize labels
train_data_KNN['income'] = train_data_KNN['income'].str.strip().str.replace('.', '')
test_data_KNN['income'] = test_data_KNN['income'].str.strip().str.replace('.', '')

# Changing income values to binary values
train_data_KNN['income'] = train_data_KNN['income'].replace({"<=50K": 0, ">50K": 1})
test_data_KNN['income'] = test_data_KNN['income'].replace({"<=50K": 0, ">50K": 1})

# Replacing the " ?" to "?" in the columns: 'work-class', 'occupation', 'native-country'
columns_to_replace = ['work-class', 'occupation', 'native-country']
for column in columns_to_replace:
    train_data_KNN[column] = train_data_KNN[column].replace(' ?', '?')
    test_data_KNN[column] = test_data_KNN[column].replace(' ?', '?')

# Concatenate train and test data
combined_data = pd.concat([train_data_KNN, test_data_KNN])

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# List of categorical columns
categorical_columns = ['work-class', 'education', 'marital-status', 'occupation',
                       'relationship', 'race', 'sex', 'native-country']

# Apply label encoding to combined data
for column in categorical_columns:
    combined_data[column] = label_encoder.fit_transform(combined_data[column])

# Split the combined data back into train and test
train_data_KNN_encoded = combined_data[:len(train_data_KNN)]
test_data_KNN_encoded = combined_data[len(train_data_KNN):]

# Extract features and target variables
X_train = train_data_KNN_encoded.drop(columns=['income'])
y_train = train_data_KNN_encoded['income']
X_test = test_data_KNN_encoded.drop(columns=['income'])
y_test = test_data_KNN_encoded['income']

# Apply Z-score normalization
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the range of k values to try
k_range = range(1, 51)

# Initialize lists to store accuracy and k values
accuracies = []
best_k_values = []

# Iterate over each value of k
for k in k_range:
    # Initialize the KNN classifier with the current value of k
    knn_classifier = KNeighborsClassifier(n_neighbors=k)

    # Train the classifier on the training data
    knn_classifier.fit(X_train_scaled, y_train)

    # Make predictions on the test data
    y_pred = knn_classifier.predict(X_test_scaled)

    # Calculate the accuracy of the classifier
    accuracy = accuracy_score(y_test, y_pred)

    # Append the accuracy and k value to the lists
    accuracies.append(accuracy)
    best_k_values.append(k)

# Get the index of the highest accuracy
best_index = accuracies.index(max(accuracies))

# Get the best k value and its corresponding accuracy
best_k = best_k_values[best_index]
best_accuracy = accuracies[best_index]
best_accuracy_percent = round(best_accuracy * 100, 2)

# Initialize the KNN classifier with the best k value
best_knn_classifier = KNeighborsClassifier(n_neighbors=best_k)

# Apply SMOTE to balance the training data
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# Train the classifier on the balanced training data
best_knn_classifier.fit(X_train_balanced, y_train_balanced)

# Make predictions on the training data using the best classifier
y_pred_train = best_knn_classifier.predict(X_train_balanced)

# Calculate the accuracy on the training data
accuracy_train = accuracy_score(y_train_balanced, y_pred_train)
accuracy_train_percent = round(accuracy_train * 100, 2)

# Calculate confusion matrix for the training data
conf_matrix_train = confusion_matrix(y_train_balanced, y_pred_train)

# Calculate precision, recall, and F1-Score for the training data
precision_train = precision_score(y_train_balanced, y_pred_train)
recall_train = recall_score(y_train_balanced, y_pred_train)
f1_train = f1_score(y_train_balanced, y_pred_train)

# Print confusion matrix, precision, recall, and F1-Score for the training data
print("\nConfusion Matrix (Training Data):")
print(conf_matrix_train)

# Print the best k value and its corresponding accuracy for both training and test data
print(f"\nBest k value: {best_k}, Training Accuracy: {accuracy_train_percent}%, Test Accuracy: {best_accuracy_percent}%")

# Print classification report for the training data
print("\nClassification Report (Training Data):")
print(classification_report(y_train_balanced, y_pred_train, target_names=["<=50K", ">50K"]))

# Make predictions on the test data using the best classifier
y_pred_best_balanced = best_knn_classifier.predict(X_test_scaled)

# Map predicted labels to their corresponding income categories
predicted_income_balanced = ["<=50K" if label == 0 else ">50K" for label in y_pred_best_balanced]

# Calculate confusion matrix for the test data
conf_matrix_balanced = confusion_matrix(y_test, y_pred_best_balanced)

# Calculate precision, recall, and F1-Score for the test data
precision_balanced = precision_score(y_test, y_pred_best_balanced)
recall_balanced = recall_score(y_test, y_pred_best_balanced)
f1_balanced = f1_score(y_test, y_pred_best_balanced)

# Print confusion matrix, precision, recall, and F1-Score for the test data
print("\nConfusion Matrix (Test Data):")
print(conf_matrix_balanced)

# Print classification report for the test data
print("\nClassification Report (Test Data):")
print(classification_report(y_test, y_pred_best_balanced, target_names=["<=50K", ">50K"]))

# Calculate the total number of predictions
total_predictions_balanced = len(predicted_income_balanced)

# Count the predictions for each income category
predictions_count_balanced = {"<=50K": predicted_income_balanced.count("<=50K"), ">50K": predicted_income_balanced.count(">50K")}

# # Print predictions count with percentages
# print("\nPredictions Count (Test Data):")
# for income_category, count in predictions_count_balanced.items():
#     percentage = (count / total_predictions_balanced) * 100
#     print(f"{income_category}: {count} ({percentage:.2f}%)")