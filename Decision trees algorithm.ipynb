{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ly_y7fFQn9r4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here, we authenticate with Google Drive to add the datafiles from a Drive folder\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.data.csv\") #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.test.csv\")  #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n",
        "# Displaying results:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdEpeDVFCuBf",
        "outputId": "05bd159d-9c27-46c8-b464-d04c3fc17e49"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Addressing the imbalanced data**"
      ],
      "metadata": {
        "id": "T8HjzvxbuPrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Undersampling"
      ],
      "metadata": {
        "id": "cm0qPHLIv8ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. SMOTE"
      ],
      "metadata": {
        "id": "L3EhH7UPz_Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is df_copy\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'marital-status' column\n",
        "train_data['marital-status'] = label_encoder.fit_transform(train_data['marital-status'])\n",
        "train_data['relationship'] = label_encoder.fit_transform(train_data['relationship'])\n",
        "train_data['race'] = label_encoder.fit_transform(train_data['race'])\n",
        "train_data['sex'] = label_encoder.fit_transform(train_data['sex'])\n",
        "## convert 'income' data to numerical values\n",
        "train_data['income'] = label_encoder.fit_transform(train_data['income'])"
      ],
      "metadata": {
        "id": "DzMVU6BoZIYF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is df_copy\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "abel_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'marital-status' column\n",
        "test_data['marital-status'] = label_encoder.fit_transform(test_data['marital-status'])\n",
        "test_data['relationship'] = label_encoder.fit_transform(test_data['relationship'])\n",
        "test_data['race'] = label_encoder.fit_transform(test_data['race'])\n",
        "test_data['sex'] = label_encoder.fit_transform(test_data['sex'])\n",
        "## convert 'income' data to numerical values\n",
        "test_data['income'] = label_encoder.fit_transform(test_data['income'])"
      ],
      "metadata": {
        "id": "x8uGoWOfR5IB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## replace 'native-country' with mode\n",
        "train_data['native-country'] = train_data['native-country'].replace('?', 'United-States')\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['native-country'] = label_encoder.fit_transform(train_data['native-country'])\n",
        "\n",
        "## replace 'work-class' with mode\n",
        "train_data['work-class'] = train_data['work-class'].replace('?', 'Private')\n",
        "train_data['work-class'] = label_encoder.fit_transform(train_data['work-class'])\n",
        "\n",
        "x_train = train_data.drop(['education','income'], axis=1)\n",
        "y_train = train_data[\"income\"]\n"
      ],
      "metadata": {
        "id": "-LTH44FOh48Q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## replace 'native-country' with mode\n",
        "test_data['native-country'] = test_data['native-country'].replace('?', 'United-States')\n",
        "label_encoder = LabelEncoder()\n",
        "test_data['native-country'] = label_encoder.fit_transform(test_data['native-country'])\n",
        "\n",
        "## replace 'work-class' with mode\n",
        "test_data['work-class'] = test_data['work-class'].replace('?', 'Private')\n",
        "test_data['work-class'] = label_encoder.fit_transform(test_data['work-class'])\n",
        "\n",
        "x_test = test_data.drop(['education','income'], axis=1)\n",
        "y_test = test_data[\"income\"]\n"
      ],
      "metadata": {
        "id": "rTNOujAiQYSZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Replace '?' with NaN in the 'occupation' column\n",
        "x_train['occupation'].replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X_train = x_train.drop('occupation', axis=1)\n",
        "y_occupation_train = x_train['occupation']\n",
        "\n",
        "\n",
        "# Apply KNN Imputer\n",
        "knn_imputer = KNNImputer()\n",
        "X_imputed_train = knn_imputer.fit_transform(X_train)\n",
        "\n",
        "# Convert imputed data back to DataFrame\n",
        "X_imputed_df_train = pd.DataFrame(X_imputed_train, columns=X_train.columns)\n",
        "\n",
        "# Combine imputed data with original data\n",
        "imputed_x_train = X_imputed_df_train.copy()\n",
        "imputed_x_train['occupation'] = y_occupation_train\n",
        "\n",
        "\n",
        "imputed_x_train['occupation'] = label_encoder.fit_transform(imputed_x_train['occupation'])\n"
      ],
      "metadata": {
        "id": "6fZP_uy4tqy9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Replace '?' with NaN in the 'occupation' column\n",
        "x_test['occupation'].replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Step 2: Separate features (X) and target variable (y)\n",
        "X_test = x_test.drop('occupation', axis=1)\n",
        "y_occupation_test = x_test['occupation']\n",
        "\n",
        "# Step 3: Apply KNN Imputer\n",
        "knn_imputer = KNNImputer()\n",
        "X_imputed_test = knn_imputer.fit_transform(X_test)\n",
        "\n",
        "# Step 4: Convert imputed data back to DataFrame\n",
        "X_imputed_df_test = pd.DataFrame(X_imputed_test, columns=X_test.columns)\n",
        "\n",
        "# Step 5: Combine imputed data with original data\n",
        "imputed_x_test = X_imputed_df_test.copy()\n",
        "imputed_x_test['occupation'] = y_occupation_test\n",
        "\n",
        "imputed_x_test['occupation'] = label_encoder.fit_transform(imputed_x_test['occupation'])\n"
      ],
      "metadata": {
        "id": "i7aViKObRAHK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(imputed_x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Initialize and train the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(imputed_x_train, y_train)\n",
        "\n",
        "y_pred_train = clf.predict(imputed_x_train)\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Accuracy on train data:\", accuracy_train)\n",
        "\n",
        "clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=0.01)  # Example value, you may need to tune this\n",
        "clf_pruned.fit(imputed_x_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test data\n",
        "y_pred_train_pruned = clf_pruned.predict(imputed_x_train)\n",
        "\n",
        "# Step 4: Evaluate the accuracy of the pruned model on the test data\n",
        "accuracy_train_pruned = accuracy_score(y_train, y_pred_train_pruned)\n",
        "print(\"Accuracy on pruned train data:\", accuracy_train_pruned)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix for regular decision tree\n",
        "conf_matrix_regular = confusion_matrix(y_train, y_pred_train)\n",
        "print(\"Confusion Matrix for Regular Decision Tree:\")\n",
        "print(\"                   Predicted Class\")\n",
        "print(\"                 |  Negative (0) | Positive (1) |\")\n",
        "print(\"Actual Class ---|---------------|---------------|\")\n",
        "print(f\"Negative (0)    |      {conf_matrix_regular[0, 0]}       |      {conf_matrix_regular[0, 1]}       |\")\n",
        "print(f\"Positive (1)    |      {conf_matrix_regular[1, 0]}       |      {conf_matrix_regular[1, 1]}       |\")\n",
        "\n",
        "# Compute confusion matrix for pruned decision tree\n",
        "conf_matrix_pruned = confusion_matrix(y_train, y_pred_train_pruned)\n",
        "print(\"\\nConfusion Matrix for Pruned Decision Tree:\")\n",
        "print(\"                   Predicted Class\")\n",
        "print(\"                 |  Negative (0) | Positive (1) |\")\n",
        "print(\"Actual Class ---|---------------|---------------|\")\n",
        "print(f\"Negative (0)    |      {conf_matrix_pruned[0, 0]}       |      {conf_matrix_pruned[0, 1]}       |\")\n",
        "print(f\"Positive (1)    |      {conf_matrix_pruned[1, 0]}       |      {conf_matrix_pruned[1, 1]}       |\")\n",
        "\n",
        "\n",
        "# Generate classification report for regular decision tree\n",
        "print(\"\\nClassification Report for Regular Decision Tree on Train Data:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Generate classification report for pruned decision tree\n",
        "print(\"\\nClassification Report for Pruned Decision Tree on Train Data:\")\n",
        "print(classification_report(y_train, y_pred_train_pruned))\n",
        "\n",
        "# Step 3: Make predictions on the test data\n",
        "y_pred_test = clf.predict(imputed_x_test)\n",
        "\n",
        "# Step 4: Evaluate the accuracy of the model on the test data\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy on test data:\", accuracy_test)\n",
        "\n",
        "# clf_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=0.01)  # Example value, you may need to tune this\n",
        "# clf_pruned.fit(imputed_x_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test data\n",
        "y_pred_test_pruned = clf_pruned.predict(imputed_x_test)\n",
        "\n",
        "# Step 4: Evaluate the accuracy of the pruned model on the test data\n",
        "accuracy_test_pruned = accuracy_score(y_test, y_pred_test_pruned)\n",
        "print(\"Accuracy on pruned test data:\", accuracy_test_pruned)\n",
        "\n",
        "# Compute confusion matrix for regular decision tree\n",
        "conf_matrix_regular = confusion_matrix(y_test, y_pred_test)\n",
        "print(\"Confusion Matrix for Regular Decision Tree:\")\n",
        "print(\"                   Predicted Class\")\n",
        "print(\"                 |  Negative (0) | Positive (1) |\")\n",
        "print(\"Actual Class ---|---------------|---------------|\")\n",
        "print(f\"Negative (0)    |      {conf_matrix_regular[0, 0]}       |      {conf_matrix_regular[0, 1]}       |\")\n",
        "print(f\"Positive (1)    |      {conf_matrix_regular[1, 0]}       |      {conf_matrix_regular[1, 1]}       |\")\n",
        "\n",
        "# Compute confusion matrix for pruned decision tree\n",
        "conf_matrix_pruned = confusion_matrix(y_test, y_pred_test_pruned)\n",
        "print(\"\\nConfusion Matrix for Pruned Decision Tree:\")\n",
        "print(\"                   Predicted Class\")\n",
        "print(\"                 |  Negative (0) | Positive (1) |\")\n",
        "print(\"Actual Class ---|---------------|---------------|\")\n",
        "print(f\"Negative (0)    |      {conf_matrix_pruned[0, 0]}       |      {conf_matrix_pruned[0, 1]}       |\")\n",
        "print(f\"Positive (1)    |      {conf_matrix_pruned[1, 0]}       |      {conf_matrix_pruned[1, 1]}       |\")\n",
        "\n",
        "\n",
        "# Generate classification report for regular decision tree\n",
        "print(\"\\nClassification Report for Regular Decision Tree on Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "# Generate classification report for pruned decision tree\n",
        "print(\"\\nClassification Report for Pruned Decision Tree on Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test_pruned))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9az_UZzyGVRU",
        "outputId": "7d9716ec-d9f1-4c12-f184-9b65b9b425be"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train data: 0.9999692884125181\n",
            "Accuracy on pruned train data: 0.8398083596941126\n",
            "Confusion Matrix for Regular Decision Tree:\n",
            "                   Predicted Class\n",
            "                 |  Negative (0) | Positive (1) |\n",
            "Actual Class ---|---------------|---------------|\n",
            "Negative (0)    |      24720       |      0       |\n",
            "Positive (1)    |      1       |      7840       |\n",
            "\n",
            "Confusion Matrix for Pruned Decision Tree:\n",
            "                   Predicted Class\n",
            "                 |  Negative (0) | Positive (1) |\n",
            "Actual Class ---|---------------|---------------|\n",
            "Negative (0)    |      23601       |      1119       |\n",
            "Positive (1)    |      4097       |      3744       |\n",
            "\n",
            "Classification Report for Regular Decision Tree on Train Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n",
            "\n",
            "Classification Report for Pruned Decision Tree on Train Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90     24720\n",
            "           1       0.77      0.48      0.59      7841\n",
            "\n",
            "    accuracy                           0.84     32561\n",
            "   macro avg       0.81      0.72      0.74     32561\n",
            "weighted avg       0.83      0.84      0.83     32561\n",
            "\n",
            "Accuracy on test data: 0.8081813156440022\n",
            "Accuracy on pruned test data: 0.839199066396413\n",
            "Confusion Matrix for Regular Decision Tree:\n",
            "                   Predicted Class\n",
            "                 |  Negative (0) | Positive (1) |\n",
            "Actual Class ---|---------------|---------------|\n",
            "Negative (0)    |      10773       |      1662       |\n",
            "Positive (1)    |      1461       |      2385       |\n",
            "\n",
            "Confusion Matrix for Pruned Decision Tree:\n",
            "                   Predicted Class\n",
            "                 |  Negative (0) | Positive (1) |\n",
            "Actual Class ---|---------------|---------------|\n",
            "Negative (0)    |      11871       |      564       |\n",
            "Positive (1)    |      2054       |      1792       |\n",
            "\n",
            "Classification Report for Regular Decision Tree on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87     12435\n",
            "           1       0.59      0.62      0.60      3846\n",
            "\n",
            "    accuracy                           0.81     16281\n",
            "   macro avg       0.73      0.74      0.74     16281\n",
            "weighted avg       0.81      0.81      0.81     16281\n",
            "\n",
            "\n",
            "Classification Report for Pruned Decision Tree on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90     12435\n",
            "           1       0.76      0.47      0.58      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.81      0.71      0.74     16281\n",
            "weighted avg       0.83      0.84      0.82     16281\n",
            "\n"
          ]
        }
      ]
    }
  ]
}